{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c91f0-cba6-4005-890c-ae31b85e3a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9390dd6-f976-4e94-8a29-21ba7b0afbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09e20839-1506-48b3-b749-87cfbd616871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_all: 8\n",
      "TP: 4\n",
      "FP: 3\n",
      "TN: 21\n",
      "FN: 4\n",
      "RI: 0.78125\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.5\n",
      "F-value: 0.5333333333333333\n",
      "ARI: 0.391304347826087\n"
     ]
    }
   ],
   "source": [
    "# yes! 聚类评估！！！可跑 TP, FP, TN, FN 得到RI、Precision、Recall、F1，ARI\n",
    "# update:单个成簇的处理\n",
    "from itertools import combinations\n",
    "from math import comb\n",
    "\n",
    "def evaluate_clustering(true_clusters, predicted_clusters):\n",
    "    def count_pairs(cluster):\n",
    "        pairs = list(combinations(cluster, 2))\n",
    "        return pairs\n",
    "\n",
    "    def compute_pairs(true_clusters, predicted_clusters):\n",
    "        TP, FP, TN, FN = 0, 0, 0, 0\n",
    "        base_plus = 0\n",
    "        for true_cluster in true_clusters:\n",
    "            flag_single = False\n",
    "            true_cluster = sorted(true_cluster)\n",
    "            true_pairs = count_pairs(true_cluster) # 排序处理，防止顺序造成偏差\n",
    "            if len(true_cluster) == 1:\n",
    "                true_pairs.append((true_cluster[0], true_cluster[0])) # 与自己组成元组\n",
    "                flag_single = True\n",
    "            # print(\"true_cluster:\",true_cluster)\n",
    "            # print(\"++++++++++++\")\n",
    "            # print(\"true_pairs:\",true_pairs)\n",
    "            # print(\"========\")\n",
    "            \n",
    "            for pair in true_pairs:\n",
    "                flag = False\n",
    "                for predicted_cluster in predicted_clusters:\n",
    "                    predicted_cluster = sorted(predicted_cluster) # 排序处理，防止顺序造成偏差\n",
    "                    predicted_pairs = count_pairs(predicted_cluster) \n",
    "                    if len(predicted_cluster) == 1:\n",
    "                        predicted_pairs.append((predicted_cluster[0], predicted_cluster[0])) # 与自己组成元组\n",
    "                    # print(\"predicted_cluster:\",predicted_cluster)\n",
    "                    # print(\"++++++++++++\")\n",
    "                    # print(\"predicted_pairs:\",predicted_pairs)\n",
    "                    if pair in predicted_pairs:\n",
    "                        TP += 1\n",
    "                        flag = True # true中同簇，在predict中有找到同簇\n",
    "                        if flag_single:\n",
    "                            base_plus+=1\n",
    "                if not flag: # flag为False，true中同簇，在predict中有找不到同簇\n",
    "                    FN += 1\n",
    "                    if flag_single:\n",
    "                        base_plus+=1\n",
    "        for predicted_cluster in predicted_clusters:\n",
    "            flag_single = False\n",
    "            predicted_cluster = sorted(predicted_cluster)\n",
    "            predicted_pairs = count_pairs(predicted_cluster) \n",
    "            if len(predicted_cluster) == 1:\n",
    "                predicted_pairs.append((predicted_cluster[0], predicted_cluster[0])) # 与自己组成元组\n",
    "                flag_single = True\n",
    "            for pair in predicted_pairs:\n",
    "                flag2 = False\n",
    "                for true_cluster in true_clusters:\n",
    "                    true_cluster = sorted(true_cluster)\n",
    "                    true_pairs = count_pairs(true_cluster)\n",
    "                    if len(true_cluster) == 1:\n",
    "                        true_pairs.append((true_cluster[0], true_cluster[0])) # 与自己组成元组\n",
    "                    if pair in true_pairs:\n",
    "                        flag2 = True\n",
    "                        break\n",
    "                if not flag2: # flag2为false,在predict中同簇，在true中不同簇(找不到同簇）\n",
    "                    FP += 1 \n",
    "                    if flag_single:\n",
    "                        base_plus+=1\n",
    "        len_all = 0\n",
    "        for true_cluster in true_clusters:\n",
    "            len_all += len(true_cluster)\n",
    "        print(\"len_all:\",len_all)\n",
    "        # total_pairs = TP + FP + FN\n",
    "        # TN = comb(total_pairs, 2) - TP - FP - FN\n",
    "        TN = comb(len_all, 2) - TP - FP - FN + base_plus # 加base_plus\n",
    "        # TN = comb(len_all, 2) - TP - FP - FN \n",
    "        return TP, FP, TN, FN\n",
    "\n",
    "    def compute_RI(TP, FP, TN, FN):\n",
    "        same_cluster_pairs = TP + TN\n",
    "        different_cluster_pairs = FP + FN\n",
    "\n",
    "        RI = same_cluster_pairs / (same_cluster_pairs + different_cluster_pairs)\n",
    "        return RI\n",
    "    \n",
    "    def compute_ARI(TP, FP, TN, FN):\n",
    "        UP = 2 * (TP*TN - FN*FP)\n",
    "        DOWN = (TP+FN)*(FN+TN) + (TP+FP)*(FP+TN)\n",
    "        ARI =  UP / DOWN \n",
    "        return ARI\n",
    "\n",
    "    def compute_precision_recall_f(TP, FP, FN):\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        f_value = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "        return precision, recall, f_value\n",
    "\n",
    "    # Compute TP, FP, TN, FN\n",
    "    TP, FP, TN, FN = compute_pairs(true_clusters, predicted_clusters)\n",
    "    print(\"TP:\",TP)\n",
    "    print(\"FP:\",FP)\n",
    "    print(\"TN:\",TN)\n",
    "    print(\"FN:\",FN)\n",
    "\n",
    "    # Compute RI\n",
    "    RI = compute_RI(TP, FP, TN, FN)\n",
    "    # Compute ARI\n",
    "    ARI = compute_ARI(TP, FP, TN, FN)\n",
    "\n",
    "    # Compute precision, recall, F-value\n",
    "    precision, recall, f_value = compute_precision_recall_f(TP, FP, FN)\n",
    "\n",
    "    return RI, precision, recall, f_value, ARI\n",
    "\n",
    "    \n",
    "\n",
    "# 示例使用\n",
    "true_clusters = [[0], [1,3,5], [2] ,[4, 6, 7]]\n",
    "predicted_clusters = [[0], [2,5],[3],[1], [4, 6, 7]]\n",
    "# predicted_clusters = [[0, 1, 2], [3, 5, 7], [4, 6]]\n",
    "# true_clusters = [[1, 2,4,5,6,7,13,17], [3, 8,9,10,12], [11,14,15,16]]\n",
    "# predicted_clusters = [[1,2,3,4,5,6], [7,8,9,10,11,12], [13,14,15,16,17]]\n",
    "\n",
    "\n",
    "RI, precision, recall, f_value, ARI = evaluate_clustering(true_clusters, predicted_clusters)\n",
    "print(\"RI:\", RI)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"ARI:\", ARI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b293ec1-58f0-43cc-92cb-6fc25e26e24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(comb(8, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7eb871c-93fb-4de9-aade-5da3ea1c14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_clusters = [[0],[1],[2,16],[3],[4,6,22,50,73,87],[5],[7],[8,61],[9],[10,77],[11],[12],[13],\n",
    " [14,29,41,51,59,67,78,84],[15],[17],[18],[19],[20],[21,68],[23],[24],[25],[26],\n",
    " [27],[28],[30],[31],[32],[33],[34],[35,55],[36],[37],[38],[39],[40],[42],[43,64],\n",
    " [44],[45],[46],[47,53,88],[48],[49],[52],[54],[56],[57],[58],[60],[62],[63],[65],\n",
    " [66],[69],[70],[71],[72],[74],[75],[76],[79],[80],[81],[82],[83],[85],[86],\n",
    " [89],[90],[91],[92],[93],[94],[95]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349bdd2f-1091-4f6c-a20d-3225a7fd42c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 5, 2, 4, 6, 7]\n",
      "[0, 2, 5, 3, 1, 4, 6, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py:746: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array = np.asarray(array, order=order, dtype=dtype)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py:746: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array = np.asarray(array, order=order, dtype=dtype)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2793/4272866085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 计算兰德系数（Rand Index，RI）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mRI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RI:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/cluster/_supervised.py\u001b[0m in \u001b[0;36mrand_score\u001b[0;34m(labels_true, labels_pred)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwiki\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mRand_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \"\"\"\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mcontingency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontingency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontingency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/cluster/_supervised.py\u001b[0m in \u001b[0;36mpair_confusion_matrix\u001b[0;34m(labels_true, labels_pred)\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspringer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10.1007\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0mFBF01908075\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_clusterings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/cluster/_supervised.py\u001b[0m in \u001b[0;36mcheck_clusterings\u001b[0;34m(labels_true, labels_pred)\u001b[0m\n\u001b[1;32m     54\u001b[0m     )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mtype_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         ):\n\u001b[0;32m--> 299\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;34m\"You appear to be using a legacy multi-label data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;34m\" representation. Sequence of sequences are no\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score, rand_score\n",
    "\n",
    "true_clusters = [[0], [1, 3, 5], [2], [4, 6, 7]]\n",
    "predicted_clusters = [[0], [2, 5], [3, 1], [4, 6, 7]]\n",
    "\n",
    "# 将簇转换为整数数组\n",
    "# true_labels = [i for sublist in true_clusters for i in sublist]\n",
    "# predicted_labels = [i for sublist in predicted_clusters for i in sublist]\n",
    "print(true_labels)\n",
    "print(predicted_labels)\n",
    "\n",
    "# 计算兰德系数（Rand Index，RI）\n",
    "RI = rand_score(true_clusters, predicted_clusters)\n",
    "print(\"RI:\", RI)\n",
    "\n",
    "# 计算调整兰德系数（Adjusted Rand Index，ARI）\n",
    "ARI = adjusted_rand_score(true_labels, predicted_labels)\n",
    "print(\"ARI:\", ARI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920fe2dc-75c7-43dc-b8e4-1ed87ffc914f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
