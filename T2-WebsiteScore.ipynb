{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fc85d2-4f2e-4be9-b517-57d262fc77f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不同的网站数量及对应的语料数已保存到 website_counts.csv 文件中。\n"
     ]
    }
   ],
   "source": [
    "# 统计不同网站个数以及对应的语料数\n",
    "# 40个网站\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '../NewsAthmTask2/datasets_FIX/FIX_deduplicated_mangoNews.csv'\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(file_path,low_memory=False,lineterminator=\"\\n\")  # 替换为你的 CSV 文件路径\n",
    "\n",
    "# 统计 website_id 列中不同项的总个数以及对应的语料数\n",
    "website_counts = df['website_id'].value_counts().reset_index()\n",
    "website_counts.columns = ['website_id', 'count']\n",
    "\n",
    "# 保存结果到新的 CSV 文件中\n",
    "website_counts.to_csv(\"./results_files/website_counts.csv\", index=False)\n",
    "\n",
    "print(\"不同的网站数量及对应的语料数已保存到 website_counts.csv 文件中。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afa76d3-8871-4cf7-be17-0c5a6a67787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "[2268, 2277, 2283, 2244, 2281, 2279, 2270, 2263, 1911, 2280, 2264, 2276, 2252, 2265, 2269, 1921, 2256, 1908, 2262, 2266, 1901, 2274, 1891, 1904, 2261, 1898, 1894, 1897, 1893, 1903, 1905, 2579, 2113, 2258, 1892, 1907, 1895, 1890, 1909, 1906]\n"
     ]
    }
   ],
   "source": [
    "website_ids_list = website_counts['website_id'].tolist()\n",
    "print(len(website_ids_list))\n",
    "print(website_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d610486f-c15b-4bce-bf0f-234bede9800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询结果已保存到 website_urls.csv 文件中。\n"
     ]
    }
   ],
   "source": [
    "# 从数据库中查询对应的网站url\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# 连接到 MySQL 数据库\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"172.16.234.200\",\n",
    "    user=\"dg_news\",\n",
    "    password=\"dg_news\",\n",
    "    database=\"common_website\"\n",
    ")\n",
    "\n",
    "# 定义要查询的 website_id 列表\n",
    "# website_ids = [1, 2, 3, ...]  # 替换为您要查询的网站id列表\n",
    "website_ids = website_ids_list\n",
    "\n",
    "# 构建 SQL 查询语句\n",
    "sql_query = f\"SELECT id, url FROM website WHERE id IN ({','.join(map(str, website_ids))})\"\n",
    "\n",
    "# 执行查询\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "\n",
    "# 获取查询结果\n",
    "query_result = cursor.fetchall()\n",
    "\n",
    "# 关闭数据库连接\n",
    "conn.close()\n",
    "\n",
    "# 将查询结果转换为 DataFrame\n",
    "df = pd.DataFrame(query_result, columns=['website_id', 'url'])\n",
    "\n",
    "# 将结果保存到新的 CSV 文件中\n",
    "df.to_csv(\"./results_files/website_id_urls.csv\", index=False)\n",
    "\n",
    "print(\"查询结果已保存到 website_urls.csv 文件中。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "357305ba-85d6-4bfb-ba3b-6694946318f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>website_id</th>\n",
       "      <th>url</th>\n",
       "      <th>S_scale</th>\n",
       "      <th>S_task_web\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1921</td>\n",
       "      <td>https://www.prothomalo.com/</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2276</td>\n",
       "      <td>https://www.prothomalo.com</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2281</td>\n",
       "      <td>https://www.jugantor.com</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>18.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2277</td>\n",
       "      <td>https://www.dhakatimes24.com</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>18.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2269</td>\n",
       "      <td>https://www.thedailystar.net</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>17.948718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  website_id                           url   S_scale  S_task_web\\r\n",
       "0     1        1921   https://www.prothomalo.com/  1.000000     20.000000\n",
       "1     1        2276    https://www.prothomalo.com  1.000000     20.000000\n",
       "2     3        2281      https://www.jugantor.com  0.948718     18.974359\n",
       "3     4        2277  https://www.dhakatimes24.com  0.923077     18.461538\n",
       "4     5        2269  https://www.thedailystar.net  0.897436     17.948718"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 40个网站的排名以及赋分结果在./T2WebsiteRank/website_Rank_new.csv\n",
    "import pandas as pd\n",
    "\n",
    "file_path = './T2WebsiteRank/website_Rank_new.csv'\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(file_path,low_memory=False,lineterminator=\"\\n\")  # 替换为你的 CSV 文件路径\n",
    "# print(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f71db66-14ca-4581-b9e8-4b19d2161e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-default",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
