{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0747a527-4bd4-4436-8bde-21da8ed40f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可跑版 使用angle-bert-base-uncased-nli-en-v1进行single-pass  ByTitle\n",
    "# update:加了评估，可对第一天结果进行评估与记录评估结果\n",
    "# updata:ByTitle\n",
    "# update：使用angle加载\n",
    "# updata:to .py :single-pass-ByTitle-angle-bert-AngleLOAD-Eval.py\n",
    "# update:保存predict_clusters\n",
    "# update:3.6 load FIX data\n",
    "# 暂时聚类最佳:angle-bert ANGLE_LOAD thresold = 0.975\n",
    "# update：3.9 新增Score计算（以angle-bert ANGLE_LOAD thresold = 0.975为例）\n",
    "import pandas as pd\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from angle_emb import AnglE\n",
    "\n",
    "\n",
    "# yes! 聚类评估！！！可跑 TP, FP, TN, FN 得到RI、Precision、Recall、F1，ARI\n",
    "# update:单个成簇的处理\n",
    "from itertools import combinations\n",
    "from math import comb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7e77b7-b7fc-4989-b104-07b0bfe65600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用angle加载\n",
    "model_id = '../NewsAthmTask2/models/angle-bert-base-uncased-nli-en-v1'\n",
    "angle = AnglE.from_pretrained(model_id, pooling_strategy='cls_avg').cuda()\n",
    "\n",
    "# 加载数据\n",
    "# data = pd.read_csv('Data231202-231211.csv')\n",
    "# data = pd.read_csv('./Data231202-231211_FIX/Data231202_newDATA.csv')\n",
    "data = pd.read_csv('./Data231202-231211/Data231202.csv')\n",
    "\n",
    "\n",
    "# 将日期转换为日期时间格式\n",
    "data['pub_time'] = pd.to_datetime(data['pub_time'])\n",
    "\n",
    "# 获取唯一日期列表\n",
    "dates = data['pub_time'].dt.date.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5522ef6e-4ed9-4c93-b5dc-82ab6cbfdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义聚类中心更新函数\n",
    "def update_cluster_center(cluster):\n",
    "    # cluster_embeddings = sbert_model.encode(cluster)\n",
    "    cluster_embeddings = angle.encode(cluster, to_numpy=True) # 使用angle加载\n",
    "     \n",
    "    return np.mean(cluster_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b668325-b01b-4018-8f56-b6bc992c0f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0], [1], [2], [3], [4, 87], [5], [6, 23], [7], [8], [9], [10, 77], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21, 68], [22, 50], [24], [25], [26], [27], [28], [29, 78], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40, 43], [41, 59], [42], [44], [45], [46], [47, 88], [48], [49], [51, 67], [52], [53], [54], [55], [56], [57], [58], [60], [61], [62], [63], [64], [65], [66], [69], [70], [71], [72], [73], [74], [75], [76], [79], [80], [81], [82], [83], [84], [85], [86], [89], [90], [91], [92], [93], [94], [95]]\n"
     ]
    }
   ],
   "source": [
    "# 设置阈值\n",
    "threshold = 0.972\n",
    "\n",
    "# 对于每个日期\n",
    "cluster_results = []\n",
    "cnt = 0\n",
    "for date in dates:\n",
    "    print(cnt)\n",
    "    cnt+=1\n",
    "    # 获取该日期的新闻标题\n",
    "    news_data = data[data['pub_time'].dt.date == date]['title'].tolist()\n",
    "    # 获取该日期的新闻正文\n",
    "    # news_data = data[data['pub_time'].dt.date == date]['body'].tolist() # ByBody\n",
    "\n",
    "    # 使用SBERT模型获取语义向量\n",
    "    # embeddings = sbert_model.encode(news_data)\n",
    "\n",
    "    embeddings = angle.encode(news_data, to_numpy=True) # 使用angle加载\n",
    "\n",
    "    # 定义当天的簇列表\n",
    "    daily_clusters = []\n",
    "\n",
    "    # 对于每个新闻数据\n",
    "    # for i, embedding in enumerate(data_vec):\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        # 如果簇列表为空，则新开一个簇\n",
    "        if not daily_clusters:\n",
    "            # daily_clusters.append({'center': embedding, 'members': [news_data[i]]})\n",
    "            daily_clusters.append({'center': embedding, 'members': [i],'news':[news_data[i]]}) # 改为存index\n",
    "            continue\n",
    "\n",
    "        # 计算当前数据点与各个簇中心的相似度\n",
    "        # similarities = [cosine_similarity([embedding], [cluster['center']])[0][0] for cluster in daily_clusters]\n",
    "        similarities = [cosine_similarity([embedding], [cluster['center']])[0][0] for cluster in daily_clusters]\n",
    "\n",
    "        # 找到最大相似度及其对应的簇索引\n",
    "        max_similarity = max(similarities)\n",
    "        max_index = similarities.index(max_similarity)\n",
    "\n",
    "        # 如果最大相似度大于阈值，则将当前数据点加入对应簇，并更新簇中心\n",
    "        if max_similarity > threshold:\n",
    "            # daily_clusters[max_index]['members'].append(news_data[i])\n",
    "            daily_clusters[max_index]['members'].append(i) # 改为存index\n",
    "            daily_clusters[max_index]['news'].append(news_data[i]) # 改为存index\n",
    "            # daily_clusters[max_index]['center'] = update_cluster_center(daily_clusters[max_index]['members'])\n",
    "            # daily_clusters[max_index]['center'] = update_cluster_center(daily_clusters[max_index]['members'],news_data)\n",
    "            daily_clusters[max_index]['center'] = update_cluster_center(daily_clusters[max_index]['news'])\n",
    "        # 否则新开一个簇\n",
    "        else:\n",
    "            # daily_clusters.append({'center': embedding, 'members': [news_data[i]]})\n",
    "            daily_clusters.append({'center': embedding, 'members': [i],'news':[news_data[i]]}) # 改为存index\n",
    "\n",
    "    # 将当天的簇信息添加到结果列表中\n",
    "    cluster_results.append({'date': date, 'clusters': daily_clusters})\n",
    "\n",
    "# 评估\n",
    "#    true_clusters = [[0],[1],[2,16],[3],[4,6,22,50,73,87],[5],[7],[8,61],[9],[10,77],[11],[12],[13],\n",
    "# [14,29,41,51,59,67,78,84],[15],[17],[18],[19],[20],[21,68],[23],[24],[25],[26],\n",
    "# [27],[28],[30],[31],[32],[33],[34],[35,55],[36],[37],[38],[39],[40],[42],[43,64],\n",
    "# [44],[45],[46],[47,53,88],[48],[49],[52],[54],[56],[57],[58],[60],[62],[63],[65],\n",
    "# [66],[69],[70],[71],[72],[74],[75],[76],[79],[80],[81],[82],[83],[85],[86],\n",
    "# [89],[90],[91],[92],[93],[94],[95]]\n",
    "\n",
    "# update:3.6 新true_clusters for FIX\n",
    "# true_clusters = [[0],[1,4,6,23,28,41],[2],[3],[5],[7],[8],[9,31],[10],[11],[12],[13],[14],[15],[16],[18],[19],[20],[17,21,38],[22],[24],[25],[26],[27],[29],[30],[32],[33],[34],[35],[36],[37],[39],[40],[42],[43],[44],[45],[46],[47],[48,49],[50],[51],[52],[53],[54],[55],[56],[57],[58],[59],[60],[61],[62],[63],[64],[65],[66],[67],[68,70,74],[69],[71],[72],[73],[75],[76],[77],[78],[79],[80]]\n",
    "\n",
    "\n",
    "predicted_clusters = []\n",
    "for cluster in cluster_results[0]['clusters']: # 2023-12-02的簇s\n",
    "    clus_index = []\n",
    "    for i in cluster['members']:\n",
    "        clus_index.append(i)\n",
    "    predicted_clusters.append(clus_index)\n",
    "print(predicted_clusters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd0c2bd-283e-469e-a5ef-3dd844218c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH!\n"
     ]
    }
   ],
   "source": [
    "# 现在我有一个列表如下所示[[0], [1], [2], [3], [4, 87], [5], [6, 23], [7], [8], [9], [10, 77], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21, 68], [22, 50], [24], [25], [26], [27], [28], [29, 78], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40, 43], [41, 59], [42], [44], [45], [46], [47, 88], [48], [49], [51, 67], [52], [53], [54], [55], [56], [57], [58], [60], [61], [62], [63], [64], [65], [66], [69], [70], [71], [72], [73], [74], [75], [76], [79], [80], [81], [82], [83], [84], [85], [86], [89], [90], [91], [92], [93], [94], [95]]\n",
    "# ，列表中每个子列表表示一个聚类的簇，子列表的元素个数即为簇中元素个数，然后我有一个语料文件'../Data231202-231211/Data231202.csv'，现在这个列表中的每个子列表的元素为该语料文件中的语料索引，现在我需要新增一列clus_news_num用来记录每个语料对应的簇中的元素个数，并将整个语料问价按语料对应的簇中的元素个数进行从大到小排序，要求同样大小的排名相同，然后在新增一列S_scale，该列内容为根据语料对应的簇中的元素个数进行归一化后的数，还有一列S_score为20*S_scale,还有一列index表示语料原始的坐标，最后将dataframe中的index，title,body,clus_news_num,S_scale，S_score这几列存入到新的csv文件中，请给出完整详细的代码\n",
    "# update:3.9 可跑！！\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 已有的聚类结果\n",
    "# clusters = [[0], [1], [2], [3], [4, 87], [5], [6, 23], [7], [8], [9], [10, 77], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21, 68], [22, 50], [24], [25], [26], [27], [28], [29, 78], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40, 43], [41, 59], [42], [44], [45], [46], [47, 88], [48], [49], [51, 67], [52], [53], [54], [55], [56], [57], [58], [60], [61], [62], [63], [64], [65], [66], [69], [70], [71], [72], [73], [74], [75], [76], [79], [80], [81], [82], [83], [84], [85], [86], [89], [90], [91], [92], [93], [94], [95]]\n",
    "clusters = predicted_clusters\n",
    "\n",
    "# 创建一个字典，键是语料索引，值是对应的簇大小\n",
    "index_to_cluster_size = {index: len(cluster) for cluster in clusters for index in cluster}\n",
    "\n",
    "# 读取语料文件\n",
    "df = pd.read_csv('./Data231202-231211/Data231202.csv')\n",
    "\n",
    "# 新增列clus_news_num，记录每个语料对应的簇的大小\n",
    "df['clus_news_num'] = df.index.map(index_to_cluster_size)\n",
    "\n",
    "# 根据簇大小进行排序，并添加排名，相同大小的排名相同\n",
    "df = df.sort_values(by='clus_news_num', ascending=False)\n",
    "df['rank'] = df['clus_news_num'].rank(method='min', ascending=False)\n",
    "\n",
    "# 新增列S_scale，为簇大小的归一化结果\n",
    "scaler = MinMaxScaler()\n",
    "df['S_scale'] = scaler.fit_transform(df[['clus_news_num']])\n",
    "\n",
    "# 新增列S_score，为S_scale的值乘以20\n",
    "df['S_score'] = df['S_scale'] * 20\n",
    "\n",
    "# 新增列index，表示语料原始的坐标\n",
    "df['ori_indexFrom0'] = df.index\n",
    "\n",
    "# 只保留需要的列，并保存到新的CSV文件\n",
    "final_df = df[['ori_indexFrom0', 'title', 'body', 'clus_news_num', 'rank','S_scale', 'S_score']]\n",
    "final_df.to_csv('./T1ClusterScore/final_result.csv', index=False)\n",
    "print(\"FINISH!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d087acd-a41d-4c5a-aa08-d8d0445d7653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-angle",
   "language": "python",
   "name": "conda-angle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
